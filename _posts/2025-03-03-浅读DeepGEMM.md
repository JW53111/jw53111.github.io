---
title: 浅读DeepGEMM
---

拜读一下 DeepGEMM，可惜身边没有方便使用的 H800，没有实机跑。一句话评价：比 CUTLASS 简洁、好上手（CUTLASS 为了兼容各种 Shape 和 Case 做了过于多的抽象，DeepGEMM 只针对自己用的Contiguous Layout），很适合阅读。比较佩服的一点是 DS 能够自信自己的工程师技术水平优于 NV CUTLASS 团队的水平，敢于开启这个项目：从代码规模来看，整个项目很可能是单挑的。

本文参考的 commit 是 [dff6bb6](https://github.com/deepseek-ai/DeepGEMM/tree/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9)，接下来逐文件分析代码结构。

## [include/deep_gemm/](https://github.com/deepseek-ai/DeepGEMM/tree/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm)

这个目录是项目的核心，包含核心 GEMM 函数及其需要的一些基本操作的 utils 封装。

### [mma_utils.cuh](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/mma_utils.cuh)

该文件封装了以 `wgmma` 为主的 PTX 指令。在阅读该文件前，推荐阅读：

- [wgmma](https://docs.nvidia.com/cuda/archive/12.6.2/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-instructions) 指令，Asynchronous Warpgroup Level Matrix Multiply-Accumulate Instructions 详细说明。

> The wgmma instructions perform warpgroup level matrix multiply-and-accumulate operation...A warpgroup is a set of four contiguous warps such that the warp-rank of the first warp is a multiple of 4.

以 [`struct SM90_64x16x32_F32E4M3E4M3_SS`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/mma_utils.cuh#L9) 为例，其封装了 `wgmma.mma_async.sync.aligned.m64n16k32.f32.e4m3.e4m3`，其含义是：

- 矩阵乘的 shape 是 `m64n16k32`。`wgmma` 指令对于 `e4m3` 、`e5m2` 的 dense 计算均要求 m=64，k=32，而n是8的倍数，大于等于 8 小于等于 256。具体的存储格式详见[这里](https://docs.nvidia.com/cuda/archive/12.6.2/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n32)，如果过于展开本文的篇幅就要爆炸了。
- `sync` 表明该指令会导致一次同步；`aligned` 表明调用该指令的线程必须调用同一地址的指令，不能在代码的不同分支分别执行。
- 两个 `e4m3` 代表输入的格式，`f32` 代表 Accumulator D的格式。相信本文的读者不需要对 `e4m3` 和 `f32` 的解释。

随后使用 [`FP8MMASelector<N>`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/mma_utils.cuh#L861) 对上述不同的 N 进行了编译期的选择。

[`warpgroup_wait<N>`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/mma_utils.cuh#L806) 封装了warpgroup的同步操作。由于一个warpgroup中有128个线程，一个block中最多1024个线程，这里N一定小于8。

还封装了一些访存指令，例如[`ld_shared`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/mma_utils.cuh#L780)。注意该函数有一个 `int4` 版本，因为 NVGPU 一次访存的宽度是 128 bit，一次读四个效率是最高的。封装仿存指令，而不是直接写 `a = b[i]` 等着编译器弄，推测作者在开发的时候需要打印访存的地址，或是尝试过修改所有访存指令，比如加 [cache operators](https://docs.nvidia.com/cuda/archive/12.6.2/parallel-thread-execution/index.html#cache-operators)。

### [tma_utils.h](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/tma_utils.cuh)

这一页的内容基本上是为了最后一个[`tma_copy<N>`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/tma_utils.cuh#L84)服务，调用 CUTLASS 中的 cute 库实现对 Hopper TMA 单元的利用。

### [utils.cuh](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/utils.cuh)

`DG_HOST_ASSERT`、`DG_DEVICE_ASSERT` 等宏； `ceil_div` 向上取整，注意是 `constexpr` 的。

### [scheduler.cuh](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/scheduler.cuh)

这个文件用于计算不同的 GEMM 算法下当前的 block 在计算哪些块。这里引用[此处](https://zhuanlan.zhihu.com/p/26437292382)的说法：

> - 常规稠密 GEMM：通过函数 deep_gemm.gemm_fp8_fp8_bf16_nt 调用，适用于常规矩阵乘法。
> - 分组 GEMM（连续布局，Contiguous Layout）：针对 MoE 模型优化，仅对 M 轴分组，N 和 K 保持固定。这种设计适用于 MoE 专家共享相同形状的情况。将多个专家的 token 拼接成单一连续张量，适用于训练前向或推理预填充阶段。每个专家段需对齐到 GEMM 的 M 块大小。
> - 分组 GEMM（掩码分组，Masked Grouped GEMM）：支持推理解码阶段，结合 CUDA Graph，适应动态 token 分配。这种分组策略与 CUTLASS 的传统分组 GEMM 不同，体现了 DeepGEMM 对 MoE 模型的针对性优化。

根据 [kernel launch](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L376) 处的启动参数，启动的 block 数量是 `num_sms`，换言之启动的block数量与m，n，k无关，运行的block需要自行决定自己的计算任务。[`get_next_block`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/scheduler.cuh#L71)将这个物理block的任务从当前逻辑block切换到下一逻辑block。核心逻辑通过 `get_swizzled_block_idx` 函数实现，该函数用于计算`m_block_idx`和`n_block_idx`。切换时将n放在较低维度，[此处的注释](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/scheduler.cuh#L48)说这样做有助于L2利用。

### [fp8_gemm.h](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh)

TBD
