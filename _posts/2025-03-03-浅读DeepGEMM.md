---
title: 浅读DeepGEMM
---

五年前我曾经[尝试](https://wu-kan.cn/2019/12/13/CUDA%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E7%9A%84%E4%BC%98%E5%8C%96/)过 Volta 上的 GEMM，能够接近当时 CUTLASS 的水平。拜读一下 DeepGEMM，可惜身边没有方便使用的 H800，没有实机跑。一句话评价：比 CUTLASS 简洁、好上手（CUTLASS 为了兼容各种 Shape 和 Case 做了过于多的抽象，DeepGEMM 只针对自己用的Contiguous Layout），很适合阅读。比较佩服的一点是 DS 能够自信自己的工程师技术水平优于 NV CUTLASS 团队的水平，敢于开启这个项目：从代码规模来看，整个项目很可能是单挑的。

本文参考的 commit 是 [dff6bb6](https://github.com/deepseek-ai/DeepGEMM/tree/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9)，接下来逐文件分析代码结构。

## [include/deep_gemm/](https://github.com/deepseek-ai/DeepGEMM/tree/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm)

这个目录是项目的核心，包含核心 GEMM 函数及其需要的一些基本操作的 utils 封装。

### [mma_utils.cuh](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/mma_utils.cuh)

该文件封装了以 `wgmma` 为主的 PTX 指令。在阅读该文件前，推荐阅读：

- [wgmma](https://docs.nvidia.com/cuda/archive/12.6.2/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-instructions) 指令，Asynchronous Warpgroup Level Matrix Multiply-Accumulate Instructions 详细说明。

> The wgmma instructions perform warpgroup level matrix multiply-and-accumulate operation...A warpgroup is a set of four contiguous warps such that the warp-rank of the first warp is a multiple of 4.

以 [`struct SM90_64x16x32_F32E4M3E4M3_SS`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/mma_utils.cuh#L9) 为例，其封装了 `wgmma.mma_async.sync.aligned.m64n16k32.f32.e4m3.e4m3`，其含义是：

- 矩阵乘的 shape 是 `m64n16k32`。`wgmma` 指令对于 `e4m3` 、`e5m2` 的 dense 计算均要求 m=64，k=32，而n是8的倍数，大于等于 8 小于等于 256。具体的存储格式详见[这里](https://docs.nvidia.com/cuda/archive/12.6.2/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n32)，如果过于展开也不过是对原文的翻译，本文的篇幅就要爆炸了。
- `sync` 表明该指令会导致一次同步；`aligned` 表明调用该指令的线程必须调用同一地址的指令，不能在代码的不同分支分别执行。
- 两个 `e4m3` 代表输入的格式，`f32` 代表 Accumulator D的格式。相信本文的读者不需要对 `e4m3` 和 `f32` 的解释。
- SS 意义不明，推测为 A 和 B 都在 SMEM 上。

随后使用 [`FP8MMASelector<N>`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/mma_utils.cuh#L861) 对上述不同的 N 进行了编译期的选择。

[`warpgroup_wait<N>`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/mma_utils.cuh#L806) 封装了warpgroup的同步操作。由于一个warpgroup中有128个线程，一个block中最多1024个线程，这里N一定小于8。

还封装了一些访存指令，例如[`ld_shared`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/mma_utils.cuh#L780)。注意该函数有一个 `int4` 版本，因为 NVGPU 一次访存的宽度是 128 bit，一次读四个效率是最高的。封装访存指令，而不是直接写 `a = b[i]` 等着编译器弄，应该是希望显式指定读取的地址是 SMEM，不要留到运行时由 `ld` 指令自己判断。

### [tma_utils.h](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/tma_utils.cuh)

这一页的内容基本上是为了最后一个[`tma_copy<N>`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/tma_utils.cuh#L84)服务，调用 CUTLASS 中的 cute 库实现对 Hopper TMA 单元的利用。

### [utils.cuh](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/utils.cuh)

`DG_HOST_ASSERT`、`DG_DEVICE_ASSERT` 等宏； `ceil_div` 向上取整，注意是 `constexpr` 的。

### [scheduler.cuh](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/scheduler.cuh)

这个文件用于计算不同的 GEMM 算法下当前的 block 在计算哪些块。这里引用[此处](https://zhuanlan.zhihu.com/p/26437292382)的说法：

> - 常规稠密 GEMM：通过函数 deep_gemm.gemm_fp8_fp8_bf16_nt 调用，适用于常规矩阵乘法。
> - 分组 GEMM（连续布局，Contiguous Layout）：针对 MoE 模型优化，仅对 M 轴分组，N 和 K 保持固定。这种设计适用于 MoE 专家共享相同形状的情况。将多个专家的 token 拼接成单一连续张量，适用于训练前向或推理预填充阶段。每个专家段需对齐到 GEMM 的 M 块大小。
> - 分组 GEMM（掩码分组，Masked Grouped GEMM）：支持推理解码阶段，结合 CUDA Graph，适应动态 token 分配。这种分组策略与 CUTLASS 的传统分组 GEMM 不同，体现了 DeepGEMM 对 MoE 模型的针对性优化。

根据 [kernel launch](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L376) 处的启动参数，启动的 block 数量是 `num_sms`，换言之启动的block数量与m、n、k无关，运行的block需要自行决定自己的计算任务（persistent kernel）。我认为这样做的好处是有利于Group GEMM，方便支持不同的 m、n。[`get_next_block`](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/scheduler.cuh#L71)将这个物理block的任务从当前逻辑block切换到下一逻辑block。核心逻辑通过 `get_swizzled_block_idx` 函数实现，该函数用于计算`m_block_idx`和`n_block_idx`。[48行的注释](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/scheduler.cuh#L48)说这样做有助于L2利用，目的是尽量使一个block计算的 C 能够共享更多的 A/B，详细推导可参考[Triton Tutorial](https://triton-lang.org/main/getting-started/tutorials/03-matrix-multiplication.html#l2-cache-optimizations)。

### [fp8_gemm.h](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh)

这个文件是整个库的核心。首先要介绍的是，这个算法使用了 WarpSpecialization (WS)，这项技术最早出现在 SC'11 的 "CudaDMA: Optimizing GPU Memory Bandwidth via Warp Specialization" 这篇文章中。简单来说，使用了 128/256 个线程做 TMA（生产者），128 个线程做计算（消费者）。这样做的好处我能想到两点：计算访存重叠（TLP相较于ILP重叠的机会更大，GEMM时活跃线程数很小，可以充分利用剩下的线程做生产者）；`sync()` 的粒度可以变小。

128 个线程做消费者比较好理解，`wgmma` 指令需要的一个 warp group 是 128个。[366 行](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L366)行有个注释，因为 153 行使用了 `setmaxnreg.aligned` 指令释放了生产者线程使用的多余的寄存器（由于 TMA 直接将数据搬到 SMEM 不经过寄存器，其需求远小于消费者线程），从而提高 Occupancy。根据 [377行](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L377)，blockDim 在 block_m 是 64 的时候是 256，要么是 384。这两个数字我这样理解：根据 [145 行](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L145) 中所说，消费者线程需要 232 个寄存器，生产者线程是 40 个寄存器，一个 block 最多使用 $128\times 232+256\times 40$ 个寄存器。一个 SM 里一共 $2048\times 32$ 个寄存器，前者是后者的一半多一点，能塞进去（但是不能塞两个）。如果没有 `setmaxnreg.aligned`，那么生产者线程最多只能有 128 个。

接下来正式进入正戏。[30行](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L30) 的几个模板参数含义如下：

```cpp
template <uint32_t SHAPE_N, uint32_t SHAPE_K, // 全局矩阵维度N和K；shape_m 是函数参数
          uint32_t BLOCK_M, uint32_t BLOCK_N, uint32_t BLOCK_K, // 线程块处理的分块维度
          uint32_t kNumGroups /* 分组数（支持 MoE 等分组 GEMM）*/, uint32_t kNumStages /* 流水线阶段数 */,
          uint32_t kNumTMAThreads /* TMA 和计算线程数 */, uint32_t kNumMathThreadsPerGroup /* TMA 多播集群大小 */,
          uint32_t kNumTMAMulticast, // TMA 多播集群大小
          GemmType kGemmType> // GEMM 类型（普通、连续分组、掩码分组）
```

[44行](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L44) 到 [127行](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L127) 在做准备工作，主要是多 Buffer 的偏移地址计算。

[132行](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L132)定义了一个 lambda，使用 `kNumStages` 阶段流水线，通过 `launch_k_iterations` 处理 K 维度的迭代，支持可整除和不可整除的 K 维度，通过模板元编程优化展开。`DivisibleK`、`NotDivisibleK` 在 [160行](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L160) 被用到，用于判断当前iter需要做多少Stage（`kNumInnerStages`）里，这个模板元体操真的绕了我一下！

```cpp
launch_k_iterations([&](int k_iter, auto type) {
    constexpr bool kHasDivisibleStages = std::is_same_v<decltype(type), DivisibleK>;
    constexpr int kNumInnerStages = kHasDivisibleStages ? kNumStages : (SHAPE_K % kFullKOfAllStages) / BLOCK_K;
    // ...
}
```

[167行](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L167)是核心的 TMA。对每个 Stage s，通过TMA Broadcast读A，通过TMA读B（没必要 Broadcast），随后对 `full_barriers[s].arrive_and_expect_tx`。[188行](https://github.com/deepseek-ai/DeepGEMM/blob/dff6bb6f0bff01c841b44e615c52e7445f8d8ee9/deep_gemm/include/deep_gemm/fp8_gemm.cuh#L188)处理未对齐的剩余的 Stage。
